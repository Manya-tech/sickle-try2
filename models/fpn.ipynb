{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import torch.nn as nn\n", "import torch"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from models.convlstm import ConvLSTM"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class FPNConvLSTM(nn.Module):\n", "    def __init__(\n", "        self,\n", "        input_dim,\n", "        num_classes,\n", "        inconv=[32, 64],\n", "        n_levels=5,\n", "        n_channels=64,\n", "        hidden_size=88,\n", "        input_shape=(128, 128),\n", "        mid_conv=True,\n", "        pad_value=0,\n", "    ):\n", "        \"\"\"\n", "        Feature Pyramid Network with ConvLSTM baseline.\n", "        Args:\n", "            input_dim (int): Number of channels in the input images.\n", "            num_classes (int): Number of classes.\n", "            inconv (List[int]): Widths of the input convolutional layers.\n", "            n_levels (int): Number of different levels in the feature pyramid.\n", "            n_channels (int): Number of channels for each channel of the pyramid.\n", "            hidden_size (int): Hidden size of the ConvLSTM.\n", "            input_shape (int,int): Shape (H,W) of the input images.\n", "            mid_conv (bool): If True, the feature pyramid is fed to a convolutional layer\n", "            to reduce dimensionality before being given to the ConvLSTM.\n", "            pad_value (float): Padding value (temporal) used by the dataloader.\n", "        \"\"\"\n", "        super(FPNConvLSTM, self).__init__()\n", "        self.pad_value = pad_value\n", "        self.inconv = ConvBlock(\n", "            nkernels=[input_dim] + inconv, norm=\"group\", pad_value=pad_value\n", "        )\n", "        self.pyramid = PyramidBlock(\n", "            input_dim=inconv[-1],\n", "            n_channels=n_channels,\n", "            n_levels=n_levels,\n", "            pad_value=pad_value,\n", "        )\n", "        if mid_conv:\n", "            dim = n_channels * n_levels // 2\n", "            self.mid_conv = ConvBlock(\n", "                nkernels=[self.pyramid.out_channels, dim],\n", "                pad_value=pad_value,\n", "                norm=\"group\",\n", "            )\n", "        else:\n", "            dim = self.pyramid.out_channels\n", "            self.mid_conv = None\n", "        self.convlstm = ConvLSTM(\n", "            input_dim=dim,\n", "            input_size=input_shape,\n", "            hidden_dim=hidden_size,\n", "            kernel_size=(3, 3),\n", "            return_all_layers=False,\n", "        )\n", "        self.outconv = nn.Conv2d(\n", "            in_channels=hidden_size, out_channels=num_classes, kernel_size=1\n", "        )\n", "    def forward(self, input, batch_positions=None):\n", "        pad_mask = (\n", "            (input == self.pad_value).all(dim=-1).all(dim=-1).all(dim=-1)\n", "        )  # BxT pad mask\n", "        pad_mask = pad_mask if pad_mask.any() else None\n", "        out = self.inconv.smart_forward(input)\n", "        out = self.pyramid.smart_forward(out)\n", "        if self.mid_conv is not None:\n", "            out = self.mid_conv.smart_forward(out)\n", "        _, out = self.convlstm(out, pad_mask=pad_mask)\n", "        out = out[0][1]\n", "        out = self.outconv(out)\n", "        return out"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class TemporallySharedBlock(nn.Module):\n", "    def __init__(self, pad_value=None):\n", "        super(TemporallySharedBlock, self).__init__()\n", "        self.out_shape = None\n", "        self.pad_value = pad_value\n", "    def smart_forward(self, input):\n", "        if len(input.shape) == 4:\n", "            return self.forward(input)\n", "        else:\n", "            b, t, c, h, w = input.shape\n", "            if self.pad_value is not None:\n", "                dummy = torch.zeros(input.shape, device=input.device).float()\n", "                self.out_shape = self.forward(dummy.view(b * t, c, h, w)).shape\n", "            out = input.view(b * t, c, h, w)\n", "            if self.pad_value is not None:\n", "                pad_mask = (out == self.pad_value).all(dim=-1).all(dim=-1).all(dim=-1)\n", "                if pad_mask.any():\n", "                    temp = (\n", "                        torch.ones(\n", "                            self.out_shape, device=input.device, requires_grad=False\n", "                        )\n", "                        * self.pad_value\n", "                    )\n", "                    temp[~pad_mask] = self.forward(out[~pad_mask])\n", "                    out = temp\n", "                else:\n", "                    out = self.forward(out)\n", "            else:\n", "                out = self.forward(out)\n", "            _, c, h, w = out.shape\n", "            out = out.view(b, t, c, h, w)\n", "            return out"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class PyramidBlock(TemporallySharedBlock):\n", "    def __init__(self, input_dim, n_levels=5, n_channels=64, pad_value=None):\n", "        \"\"\"\n", "        Feature Pyramid Block. Performs atrous convolutions with different strides\n", "        and concatenates the resulting feature maps along the channel dimension.\n", "        Args:\n", "            input_dim (int): Number of channels in the input images.\n", "            n_levels (int): Number of levels.\n", "            n_channels (int): Number of channels per level.\n", "            pad_value (float): Padding value (temporal) used by the dataloader.\n", "        \"\"\"\n", "        super(PyramidBlock, self).__init__(pad_value=pad_value)\n", "        dilations = [2 ** i for i in range(n_levels - 1)]\n", "        self.inconv = nn.Conv2d(input_dim, n_channels, kernel_size=3, padding=1)\n", "        self.convs = nn.ModuleList(\n", "            [\n", "                nn.Conv2d(\n", "                    in_channels=n_channels,\n", "                    out_channels=n_channels,\n", "                    kernel_size=3,\n", "                    stride=1,\n", "                    dilation=d,\n", "                    padding=d,\n", "                    padding_mode=\"reflect\",\n", "                )\n", "                for d in dilations\n", "            ]\n", "        )\n", "        self.out_channels = n_levels * n_channels\n", "    def forward(self, input):\n", "        out = self.inconv(input)\n", "        global_avg_pool = out.view(*out.shape[:2], -1).max(dim=-1)[0]\n", "        out = torch.cat([cv(out) for cv in self.convs], dim=1)\n", "        h, w = out.shape[-2:]\n", "        out = torch.cat(\n", "            [\n", "                out,\n", "                global_avg_pool.unsqueeze(-1)\n", "                .repeat(1, 1, h)\n", "                .unsqueeze(-1)\n", "                .repeat(1, 1, 1, w),\n", "            ],\n", "            dim=1,\n", "        )\n", "        return out"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class ConvLayer(nn.Module):\n", "    def __init__(self, nkernels, norm=\"batch\", k=3, s=1, p=1, n_groups=4):\n", "        super(ConvLayer, self).__init__()\n", "        layers = []\n", "        if norm == \"batch\":\n", "            nl = nn.BatchNorm2d\n", "        elif norm == \"instance\":\n", "            nl = nn.InstanceNorm2d\n", "        elif norm == \"group\":\n", "            nl = lambda num_feats: nn.GroupNorm(\n", "                num_channels=num_feats, num_groups=n_groups\n", "            )\n", "        else:\n", "            nl = None\n", "        for i in range(len(nkernels) - 1):\n", "            layers.append(\n", "                nn.Conv2d(\n", "                    in_channels=nkernels[i],\n", "                    out_channels=nkernels[i + 1],\n", "                    kernel_size=k,\n", "                    padding=p,\n", "                    stride=s,\n", "                    padding_mode=\"reflect\",\n", "                )\n", "            )\n", "            if nl is not None:\n", "                layers.append(nl(nkernels[i + 1]))\n", "            layers.append(nn.ReLU())\n", "        self.conv = nn.Sequential(*layers)\n", "    def forward(self, input):\n", "        return self.conv(input)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class ConvBlock(TemporallySharedBlock):\n", "    def __init__(self, nkernels, pad_value=None, norm=\"batch\"):\n", "        super(ConvBlock, self).__init__(pad_value=pad_value)\n", "        self.conv = ConvLayer(nkernels=nkernels, norm=norm)\n", "    def forward(self, input):\n", "        return self.conv(input)"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}